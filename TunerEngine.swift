import SwiftUI
import AVFoundation
import Combine

class TunerEngine: ObservableObject {
    private var engine: AVAudioEngine
    private var mic: AVAudioInputNode
    private var player: AVAudioPlayerNode
    
    let noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
    
    @Published var data = TunerData()
    @Published var isPlaying = false
    @Published var standardFrequency: Double = 440.0
    @Published var errorMessage: String?
    
    // æ€§èƒ½ä¼˜åŒ–ï¼šå¤ç”¨ç¼“å†²åŒº
    private var sampleBuffer: [Float] = []
    
    // éŸ³é¢‘å¤„ç†é˜Ÿåˆ— - ä½¿ç”¨ä¸²è¡Œé˜Ÿåˆ—ç¡®ä¿æ“ä½œé¡ºåº
    private let audioQueue = DispatchQueue(label: "com.tuner.audio", qos: .userInitiated)
    
    // çº¿ç¨‹å®‰å…¨é”
    private let lock = NSLock()
    
    // å½“å‰æ’­æ”¾é¢‘ç‡ï¼Œç”¨äºçƒ­åˆ‡æ¢
    private var currentPlayingFrequency: Double = 0
    
    // ç¼“å†²åŒºè°ƒåº¦æ§åˆ¶
    private var shouldContinueScheduling = false
    
    // éŸ³é«˜å¹³æ»‘å¤„ç†
    private var smoothedPitch: Double = 0
    
    // èŠ‚æ‹å™¨å¯èƒ½ä½¿ç”¨çš„é¢‘ç‡ï¼ˆç”¨äºè¿‡æ»¤å¹²æ‰°ï¼‰
    private let metronomeFrequencies: [Double] = [1200, 800, 2000, 1500, 600, 400, 1000, 750, 1600]
    
    struct TunerData {
        var pitch: Double = 0.0
        var amplitude: Double = 0.0
        var noteName: String = "--"
        var deviation: Double = 0.0
    }
    
    init() {
        engine = AVAudioEngine()
        mic = engine.inputNode
        player = AVAudioPlayerNode()
        engine.attach(player)
        engine.connect(player, to: engine.mainMixerNode, format: nil)
        
        // åŠ è½½ä¸Šæ¬¡çš„æ ‡å‡†é¢‘ç‡
        let savedFreq = UserDefaults.standard.double(forKey: UserDefaultsKeys.lastStandardFrequency)
        if savedFreq > 0 {
            standardFrequency = savedFreq
        }
        
        setupAudioSession()
    }
    
    deinit {
        // ä¿å­˜æ ‡å‡†é¢‘ç‡
        UserDefaults.standard.set(standardFrequency, forKey: UserDefaultsKeys.lastStandardFrequency)
        
        // ã€æ–°å¢ã€‘æ¸…ç†éŸ³é¢‘èµ„æº
        stopPlaying()
        stopListening()
        
        // åœæ­¢å¼•æ“
        if engine.isRunning {
            engine.stop()
        }
        
        print("ğŸ§¹ TunerEngine å·²æ¸…ç†")
    }
    
    func setupAudioSession() {
        AudioSessionManager.shared.configureForPlayAndRecord()
        DispatchQueue.main.async {
            self.errorMessage = nil
        }
    }
    
    func startListening() {
        stopPlaying()
        if engine.isRunning {
            engine.stop()
        }
        engine.reset()
        
        // ã€æ–°å¢ã€‘åœ¨è·å–è¾“å…¥æ ¼å¼å‰å…ˆè®¾ç½®éŸ³é¢‘ä¼šè¯
        setupAudioSession()
        
        let format = mic.inputFormat(forBus: 0)
        guard format.sampleRate > 0 else {
            print("âŒ Invalid microphone format: sampleRate = \(format.sampleRate)")
            DispatchQueue.main.async {
                self.errorMessage = AudioError.deviceNotAvailable.localizedDescription
            }
            return
        }
        
        print("âœ… Microphone format: \(format.sampleRate) Hz, \(format.channelCount) channels")
        
        mic.removeTap(onBus: 0)
        
        // ä½¿ç”¨å¸¸é‡é…ç½®ç¼“å†²åŒºå¤§å°
        mic.installTap(onBus: 0, bufferSize: AudioConstants.bufferSize, format: format) { [weak self] (buffer, time) in
            self?.processAudio(buffer: buffer)
        }
        
        do {
            try engine.start()
            DispatchQueue.main.async {
                self.errorMessage = nil
            }
        } catch {
            print("âš ï¸ TunerEngine start error: \(error)")
            DispatchQueue.main.async {
                self.errorMessage = AudioError.engineStartFailed.localizedDescription
            }
        }
    }
    
    func stopListening() {
        mic.removeTap(onBus: 0)
        engine.stop()
        DispatchQueue.main.async { self.data = TunerData() }
    }
    
    func playTone(frequency: Double) {
        // é˜²æ­¢é‡å¤è°ƒç”¨ç›¸åŒé¢‘ç‡
        if isPlaying && abs(frequency - currentPlayingFrequency) < 0.1 {
            return
        }
        
        currentPlayingFrequency = frequency
        
        // åœ¨éŸ³é¢‘é˜Ÿåˆ—ä¸­æ‰§è¡Œï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
        audioQueue.async { [weak self] in
            guard let self = self else { return }
            
            self.lock.lock()
            defer { self.lock.unlock() }
            
            // åœæ­¢è°ƒåº¦å¾ªç¯
            self.shouldContinueScheduling = false
            
            // åœæ­¢ç›‘å¬
            if self.mic.numberOfInputs > 0 {
                self.mic.removeTap(onBus: 0)
            }
            
            // åœæ­¢æ’­æ”¾å™¨
            self.player.stop()
            
            // åœæ­¢å¼•æ“ï¼ˆç§»é™¤ sleepï¼ŒAVAudioEngine.stop() æ˜¯åŒæ­¥çš„ï¼‰
            if self.engine.isRunning {
                self.engine.stop()
            }
            
            // æ–­å¼€è¿æ¥
            self.engine.disconnectNodeOutput(self.player)
            
            // åˆ›å»ºæ–°çš„éŸ³é¢‘æ ¼å¼å’Œç¼“å†²åŒº
            let format = AVAudioFormat(standardFormatWithSampleRate: AudioConstants.sampleRate, channels: 1)!
            guard let buffer = self.createSineWave(frequency: frequency, sampleRate: AudioConstants.sampleRate, format: format) else {
                DispatchQueue.main.async {
                    self.errorMessage = "åˆ›å»ºéŸ³é¢‘ç¼“å†²åŒºå¤±è´¥"
                    self.isPlaying = false
                }
                return
            }
            
            // é‡æ–°è¿æ¥
            self.engine.connect(self.player, to: self.engine.mainMixerNode, format: format)
            
            do {
                try self.engine.start()
                
                // å¯åŠ¨è°ƒåº¦å¾ªç¯
                self.shouldContinueScheduling = true
                self.scheduleBufferLoop(buffer: buffer)
                
                // å¼€å§‹æ’­æ”¾
                self.player.play()
                
                DispatchQueue.main.async {
                    self.isPlaying = true
                    self.errorMessage = nil
                }
            } catch {
                print("Engine start error: \(error)")
                DispatchQueue.main.async {
                    self.errorMessage = AudioError.engineStartFailed.localizedDescription
                    self.isPlaying = false
                }
            }
        }
    }
    
    private func scheduleBufferLoop(buffer: AVAudioPCMBuffer) {
        guard shouldContinueScheduling else { return }
        
        // é¢„å…ˆè°ƒåº¦5ä¸ªç¼“å†²åŒºï¼Œæ¯ä¸ªå®Œæˆåä¼šè§¦å‘å›è°ƒè¡¥å……
        for _ in 0..<5 {
            scheduleNextBuffer(buffer)
        }
    }
    
    private func scheduleNextBuffer(_ buffer: AVAudioPCMBuffer) {
        // å…³é”®ä¿®å¤ï¼šåªæ£€æŸ¥ shouldContinueSchedulingï¼Œä¸æ£€æŸ¥ isPlaying
        // å› ä¸º isPlaying å¯èƒ½åœ¨ä¸»çº¿ç¨‹æ›´æ–°æœ‰å»¶è¿Ÿ
        guard shouldContinueScheduling else { return }
        
        player.scheduleBuffer(buffer) { [weak self] in
            guard let self = self else { return }
            // å…³é”®ï¼šæ¯ä¸ªç¼“å†²åŒºæ’­æ”¾å®Œæˆåï¼Œé€’å½’è°ƒåº¦ä¸‹ä¸€ä¸ª
            // è¿™æ ·å°±èƒ½æ— é™å¾ªç¯æ’­æ”¾
            self.scheduleNextBuffer(buffer)
        }
    }
    
    func stopPlaying() {
        audioQueue.async { [weak self] in
            guard let self = self else { return }
            
            self.lock.lock()
            defer { self.lock.unlock() }
            
            // åœæ­¢è°ƒåº¦å¾ªç¯
            self.shouldContinueScheduling = false
            
            // åœæ­¢æ’­æ”¾å™¨
            self.player.stop()
            
            DispatchQueue.main.async {
                self.isPlaying = false
            }
        }
    }
    
    private func createSineWave(frequency: Double, sampleRate: Double, format: AVAudioFormat) -> AVAudioPCMBuffer? {
        // ç²¾ç¡®ç”Ÿæˆæ­£å¼¦æ³¢ï¼Œæ¶ˆé™¤ç›¸ä½ä¸è¿ç»­å¯¼è‡´çš„æ‚éŸ³
        
        let samplesPerCycle = sampleRate / frequency
        
        // è®¡ç®—éœ€è¦å¤šå°‘ä¸ªå®Œæ•´å‘¨æœŸæ‰èƒ½è®©ç¼“å†²åŒºè¶³å¤Ÿé•¿ï¼ˆçº¦0.5ç§’ï¼‰
        let desiredDuration: Double = 0.5
        let cycles = round(desiredDuration * frequency)
        
        // å¸§æ•° = å‘¨æœŸæ•° Ã— æ¯å‘¨æœŸé‡‡æ ·ç‚¹æ•°
        let frameCount = AVAudioFrameCount(cycles * samplesPerCycle)
        
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else { return nil }
        buffer.frameLength = frameCount
        
        guard let channels = buffer.floatChannelData else { return nil }
        let samples = channels[0]
        
        // å…³é”®ä¿®å¤ï¼šä½¿ç”¨å‘¨æœŸå½’ä¸€åŒ–çš„æ–¹å¼ç”Ÿæˆæ³¢å½¢
        // ç¡®ä¿æœ€åä¸€ä¸ªé‡‡æ ·ç‚¹å’Œç¬¬ä¸€ä¸ªé‡‡æ ·ç‚¹ç›¸ä½è¿ç»­
        let totalSamples = Int(frameCount)
        
        for i in 0..<totalSamples {
            // æ–¹æ³•1ï¼šåŸºäºæ€»å‘¨æœŸæ•°å½’ä¸€åŒ–ï¼ˆæ›´ç²¾ç¡®ï¼‰
            // å°†æ•´ä¸ªç¼“å†²åŒºåˆ†æˆ cycles ä¸ªå®Œæ•´å‘¨æœŸ
            let normalizedPosition = Double(i) / Double(totalSamples)  // 0.0 åˆ° 1.0
            let phase = 2.0 * .pi * cycles * normalizedPosition
            let sample = Float(sin(phase)) * 0.5
            samples[i] = sample
        }
        
        #if DEBUG
        // éªŒè¯ç›¸ä½è¿ç»­æ€§ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ï¼‰
        let firstSample = samples[0]
        let lastSample = samples[totalSamples - 1]
        let continuityError = abs(lastSample - firstSample)
        
        if continuityError > 0.001 {
            print("âš ï¸ é¢‘ç‡ \(String(format: "%.2f", frequency))Hz - ç›¸ä½å·®: \(String(format: "%.6f", continuityError))")
        }
        #endif
        
        return buffer
    }
    
    private func processAudio(buffer: AVAudioPCMBuffer) {
        guard let channelData = buffer.floatChannelData?[0] else { return }
        let frameLength = Int(buffer.frameLength)
        
        // æ€§èƒ½ä¼˜åŒ–ï¼šåœ¨æ ˆä¸Šåˆ›å»ºä¸´æ—¶ç¼“å†²åŒºï¼Œé¿å…ç«äº‰æ¡ä»¶
        // ç”±äºéŸ³é¢‘å›è°ƒåœ¨ä¸“ç”¨çº¿ç¨‹ï¼Œä½¿ç”¨å±€éƒ¨å˜é‡æ›´å®‰å…¨
        var localBuffer = sampleBuffer
        if localBuffer.count != frameLength {
            localBuffer = [Float](repeating: 0, count: frameLength)
            sampleBuffer = localBuffer  // æ›´æ–°å…±äº«ç¼“å†²åŒº
        }
        
        // å¤åˆ¶æ•°æ®åˆ°ç¼“å†²åŒº
        for i in 0..<frameLength {
            localBuffer[i] = channelData[i]
        }
        
        // 1. è®¡ç®— RMS (éŸ³é‡/æŒ¯å¹…)
        var sum: Float = 0
        for sample in localBuffer {
            sum += sample * sample
        }
        let rms = sqrt(sum / Float(frameLength))
        
        // 2. è®¡ç®—è¿‡é›¶ç‡ (Zero-Crossing)
        // è¿™ç§ç®—æ³•æ¯” FFT ç®€å•ï¼Œå®ƒæ˜¯é€šè¿‡æ•°æ³¢å½¢ç©¿è¿‡ 0 è½´çš„æ¬¡æ•°æ¥ä¼°ç®—é¢‘ç‡
        var zeroCrossings = 0
        var previousSign = localBuffer[0] > 0
        for sample in localBuffer {
            let currentSign = sample > 0
            if currentSign != previousSign {
                zeroCrossings += 1
                previousSign = currentSign
            }
        }
        
        let frequency = Double(zeroCrossings) * buffer.format.sampleRate / (2.0 * Double(frameLength))
        
        // 3. å™ªéŸ³é—¨é™ï¼šåªæœ‰éŸ³é‡å¤§äºé˜ˆå€¼æ‰æ›´æ–°éŸ³é«˜
        // ã€æ–°å¢ã€‘æé«˜é˜ˆå€¼ï¼Œè¿‡æ»¤æ‰èŠ‚æ‹å™¨çš„çŸ­ä¿ƒéŸ³
        let isMetronomeRunning = MetronomeStateManager.shared.isPlaying
        let dynamicThreshold = isMetronomeRunning
        ? AudioConstants.rmsThreshold * 1.8
        : AudioConstants.rmsThreshold * 1.3
        
        if Double(rms) > dynamicThreshold {
            analyzePitch(frequency: frequency, amplitude: Double(rms))
        } else {
            DispatchQueue.main.async { self.data.amplitude = Double(rms) }
        }
    }
    
    private func analyzePitch(frequency: Double, amplitude: Double) {
        // ã€ä¼˜åŒ– 1ã€‘è¿‡æ»¤æ‰èŠ‚æ‹å™¨çš„é«˜é¢‘éŸ³ï¼ˆ800-2000 Hzï¼‰
        // èŠ‚æ‹å™¨é€šå¸¸ä½¿ç”¨é«˜é¢‘çŸ­ä¿ƒéŸ³ï¼Œä¸ä¹å™¨éŸ³è‰²ä¸åŒ
        let isLikelyMetronome = frequency > 700.0 && frequency < 2100.0 && amplitude < 0.3
        
        if isLikelyMetronome {
            // å¿½ç•¥ç–‘ä¼¼èŠ‚æ‹å™¨çš„å£°éŸ³
            return
        }
        
        // ã€ä¼˜åŒ– 1.1ã€‘å¦‚æœèŠ‚æ‹å™¨æ­£åœ¨æ’­æ”¾ï¼Œè¿‡æ»¤æ¥è¿‘èŠ‚æ‹å™¨é¢‘ç‡çš„çªåˆº
        if MetronomeStateManager.shared.isPlaying {
            let isNearMetronomeTone = metronomeFrequencies.contains { abs(frequency - $0) < 25.0 }
            if isNearMetronomeTone && amplitude < 0.55 {
                return
            }
            
            // èŠ‚æ‹ç¬é—´æŠ‘åˆ¶ï¼ˆå‡å°‘æŠ–åŠ¨ï¼‰
            if MetronomeStateManager.shared.isVisualPulse && amplitude < 0.45 {
                return
            }
        }
        
        // ã€ä¼˜åŒ– 2ã€‘è¿‡æ»¤æ‰äººè€³å¬ä¸åˆ°çš„æç«¯é¢‘ç‡
        guard frequency > AudioConstants.minFrequency && frequency < AudioConstants.maxFrequency else { return }
        
        let baseFreq = self.standardFrequency
        
        // ã€ä¼˜åŒ– 3ã€‘éŸ³é«˜å¹³æ»‘å¤„ç†ï¼Œå‡å°‘èŠ‚æ‹å™¨å½±å“ä¸‹çš„æŠ–åŠ¨
        let smoothingFactor = MetronomeStateManager.shared.isPlaying ? 0.2 : 0.35
        if smoothedPitch == 0 {
            smoothedPitch = frequency
        } else {
            smoothedPitch += (frequency - smoothedPitch) * smoothingFactor
        }
        
        let stableFrequency = smoothedPitch
        
        let semitones = 12.0 * log2(stableFrequency / baseFreq)
        let noteNumDouble = semitones + 69.0
        let roundedNoteNum = Int(round(noteNumDouble))
        let diff = noteNumDouble - Double(roundedNoteNum)
        let deviationCents = 100.0 * diff
        
        var index = roundedNoteNum % 12
        if index < 0 { index += 12 }
        
        DispatchQueue.main.async {
            self.data.pitch = stableFrequency
            self.data.noteName = self.noteNames[index]
            self.data.deviation = deviationCents
            self.data.amplitude = amplitude
        }
    }
}
